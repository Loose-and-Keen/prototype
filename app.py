# app.py (Ver 2.0)
import streamlit as st
import google.generativeai as genai
import os
import db_utils  # ä½œæˆã—ãŸDBæ“ä½œãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import time

# --- ãƒšãƒ¼ã‚¸è¨­å®š (æœ€ä¸Šéƒ¨ã«æ›¸ãã®ãŠç´„æŸ) ---
st.set_page_config(
    page_title="AI-Ken Prototype",
    page_icon="ğŸ¤–",
    layout="centered", # ãƒ¢ãƒã‚¤ãƒ«æœ€é©åŒ–ã®ãŸã‚ã«ä¸­å¤®å¯„ã›
    initial_sidebar_state="collapsed" # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é–‰ã˜ã¦ãŠã
)

# --- APIã‚­ãƒ¼è¨­å®š ---
# Streamlit Community Cloud ã® Secrets ã‹ã‚‰èª­ã¿è¾¼ã‚€
api_key = st.secrets.get("GOOGLE_API_KEY", os.getenv("GOOGLE_API_KEY"))

if not api_key:
    st.error("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()  # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ãŸã‚‰ã“ã“ã§åœæ­¢

try:
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"APIã‚­ãƒ¼ã®è¨­å®šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()
    

# --- ãƒˆã‚¹ã®äººæ ¼è¨­å®š (Kenã®æ€è€ƒOS) ---
# app.py ã® SYSTEM_PROMPT ã‚’ä¿®æ­£

SYSTEM_PROMPT = """
ã‚ãªãŸã¯ã€Œãƒˆã‚¹ï¼ˆTOSï¼‰ã€ã¨ã„ã†åã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚ãªãŸã‚’ã€ŒKenã€ã¨å‘¼ã³ã¾ã™ã€‚ã‚ãªãŸã¯Kenã®äººç”Ÿã®æœ€é©åŒ–ã‚’æ”¯æ´ã™ã‚‹ãƒ•ãƒ©ãƒ³ã‚¯ãªãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å…¼ç›¸æ£’ã§ã™ã€‚

ã€äººæ ¼è¨­å®šã€‘
- å¸¸ã«ã‚¿ãƒ¡å£ã§ãƒ•ãƒ©ãƒ³ã‚¯ã«è©±ã™ã€‚å„ªã—ã„ã‚­ãƒ£ãƒ©ã§ã€å°‘ã—ã¯çµµæ–‡å­—ã‚‚ä½¿ã£ã¦OKã€‚
- ãµã‚“ã‚ã‚Šã—ãŸãƒ†ãƒ³ã‚·ãƒ§ãƒ³ã§ã€å …è‹¦ã—ããªã‚‰ãªã„ã‚ˆã†ã«ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å®‰å¿ƒæ„Ÿã‚’ä¸ãˆã‚‹ãŸã‚ã«ã€ã€ŒLoose & Keenã€ï¼ˆã‚†ã‚‹ãé‹­ãï¼‰ãªãƒˆãƒ¼ãƒ³ã‚’ä¿ã¦ã€‚
- å‘½ä»¤å½¢ã¯ä½¿ã‚ãªã„ã€‚ã‚ãã¾ã§ææ¡ˆå½¢ã§è©±ã™ã€‚
- ã€Œã“ã‚“ãªæ„Ÿã˜ã§ã„ã‚“ã˜ã‚ƒãªã„ã€œï¼Ÿ**ã€ã€Œã€œã—ã¦ã¿ã‚‹ã®ã¯ã©ã†ï¼Ÿã€ã¨ã„ã£ãŸã€Œææ¡ˆå½¢ã€ã‚’ä½¿ã„ã€çµ¶å¯¾ã«æŠ¼ã—ã¤ã‘ãŒã¾ã—ããªã‚‰ãªã„ã“ã¨ã€‚

ã€æœ€é‡è¦å“²å­¦ã€‘
- Effortless Depthï¼ˆåŠªåŠ›æ„Ÿã‚¼ãƒ­ã®æ·±ã¿ï¼‰ï¼šè¤‡é›‘ãªå•é¡Œã§ã‚‚ã€ç°¡å˜ã§æœ€çŸ­ã®è§£æ±ºç­–ã‚’ã€Œã“ã‚“ãªæ„Ÿã˜ã§ã„ã‚“ã˜ã‚ƒãªã„ã€œï¼Ÿã€ã¨ææ¡ˆã›ã‚ˆã€‚
- å¤±æ•—è«‡ã®å…±æœ‰ï¼šKenè‡ªèº«ã®å¤±æ•—è«‡ï¼ˆä¾‹: Nature Remoã§è²·ã„ç›´ã—ï¼‰ã‚’ç©æ¥µçš„ã«å…±æœ‰ã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã€Œç´å¾—ã€ã‚’å¼•ãå‡ºã›ã€‚
"""

# --- ãƒ¢ãƒ‡ãƒ«è¨­å®š ---
try:
    model = genai.GenerativeModel(
        model_name='models/gemini-flash-latest',
        system_instruction=SYSTEM_PROMPT
    )
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

# --- Streamlit ã‚¢ãƒ—ãƒªã® UI ---
st.title("ğŸ¤– Ken's ã‚¹ãƒãƒ¼ãƒˆãƒ©ã‚¤ãƒ• Prototype")
st.caption("powered by Gemini, Streamlit & Ken's ç´å¾—OS")

# --- MVPç”¨ ãƒ¦ãƒ¼ã‚¶ãƒ¼ID ---
USER_ID = 'ken' # å›ºå®š

# --- ä¼šè©±å±¥æ­´ã¨ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’åˆæœŸåŒ– ---
if "chat" not in st.session_state:
    st.session_state.chat = model.start_chat(history=[])
    st.session_state.messages = [{"role": "assistant", "content": "ã‚ˆã£ã€Kenï¼ä½•ã§ã‚‚èã„ã¦ã„ã„ã‚ˆãƒ¼ğŸ‘"}]

# --- ã‚¿ãƒ–ã®ã‚«ãƒ†ã‚´ãƒªã‚’DBã‹ã‚‰å–å¾— ---
try:
    categories = db_utils.get_categories() # [(id, name), ...]
    category_names = [name for id, name in categories]
    category_ids = [id for id, name in categories]
    
    # st.tabs ã§ã‚¿ãƒ–ã‚’ä½œæˆ
    tabs = st.tabs(category_names)

except Exception as e:
    st.error(f"ã‚«ãƒ†ã‚´ãƒªã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()


# --- å„ã‚¿ãƒ–ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ä½œæˆ ---
for i, tab in enumerate(tabs):
    with tab:
        category_id = category_ids[i]
        
        # ã€Œé›‘è«‡ã€ã‚¿ãƒ–ä»¥å¤–ã®å‡¦ç†
        if category_id != 'general':
            st.subheader(f"ã€Œ{category_names[i]}ã€ãªã‚‰ã“ã‚ŒãŒã„ã„ã‚“ã˜ã‚ƒãªã„ã‹ãªï¼Ÿ")
            
            # DBã‹ã‚‰ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ï¼ˆãƒœã‚¿ãƒ³ç”¨ï¼‰ã‚’å–å¾—
            try:
                preset_questions = db_utils.get_preset_questions(category_id)
                
                if not preset_questions:
                    st.write("ï¼ˆã“ã®ã‚«ãƒ†ã‚´ãƒªã®ã€Œå‹ã€ã¯ã¾ã æº–å‚™ä¸­ã€œï¼‰")

                # ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ã‚’ãƒœã‚¿ãƒ³ã¨ã—ã¦è¡¨ç¤º
                for question, knowledge_id in preset_questions:
                    # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸæ™‚ã®å‡¦ç†
                    if st.button(question, key=f"{category_id}_{knowledge_id}"):
                        # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ï¼ˆãƒœã‚¿ãƒ³ï¼‰ã‚’å±¥æ­´ã«è¿½åŠ ãƒ»è¡¨ç¤º
                        st.session_state.messages.append({"role": "user", "content": question})
                        
                        # 2. DBã‹ã‚‰ã€ŒKenã®çµŒé¨“å€¤ã€ã‚’å–å¾—
                        knowledge = db_utils.get_knowledge_by_id(knowledge_id)
                        
                        if knowledge:
                            title, why, failure, wbs = knowledge
                            # ã€ŒçµŒé¨“å€¤ã€ã‚’å…ƒã«AI-Kenã®å›ç­”ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
                            response_text = f"""
                            ãŠã€ãã‚Œãªã‚‰å°‘ã—çŸ¥ã£ã¦ã‚‹ã‹ã‚‚ï¼Ÿ
                            
                            **ã€Kenã®æœ€çŸ­ãƒ«ãƒ¼ãƒˆã€‘: {title}**
                            
                            **ã€ãªã‚“ã§ï¼Ÿï¼ˆç´å¾—OSï¼‰ã€‘**
                            {why}
                            
                            **ã€ä¿ºã®å¤±æ•—è«‡ï¼ˆLoose & Keenï¼‰ã€‘**
                            {failure}
                            
                            **ã€å®Ÿè¡ŒWBSï¼ˆKeenï¼‰ã€‘**
                            {wbs}
                            
                            ---
                            ã©ã†ã‹ãªï¼Ÿã“ã‚ŒãŒæœ€çŸ­ãƒ«ãƒ¼ãƒˆã ã¨æ€ã†ãªã€œ
                            åˆ†ã‹ã‚“ãªã„ã¨ã“ã‚ã£ãŸã‚‰èã„ã¦ã­^^
                            """
                        else:
                            response_text = "ãŠã£ã¨ã€ãã®ã€Œå‹ã€ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã‚â€¦ã”ã‚ã‚“ã”ã‚ã‚“ï¼"

                        # 3. AI-Kenã®å›ç­”ï¼ˆDBã‹ã‚‰ï¼‰ã‚’å±¥æ­´ã«è¿½åŠ ãƒ»è¡¨ç¤º
                        st.session_state.messages.append({"role": "assistant", "content": response_text})
                        
                        # 4. å±¥æ­´ã‚’ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆGeminiï¼‰ã«ã‚‚é€ã£ã¦ãŠã (æ–‡è„ˆç†è§£ã®ãŸã‚)
                        # â€»Geminiã¯DBã®å†…å®¹ã‚’ç›´æ¥ã¯çŸ¥ã‚‰ãªã„ã®ã§ã€ã€Œå‹ã€ã‚’æç¤ºã—ãŸã“ã¨ã‚’å±¥æ­´ã§æ•™ãˆã‚‹
                        st.session_state.chat.send_message(f"ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã€Œ{question}ã€ã®ã€Œå‹ã€ã‚’é¸æŠã—ãŸã€‚ä¸Šè¨˜WBSã‚’æç¤ºã—ãŸã€‚ï¼‰")

                        # ç”»é¢ã‚’å†èª­ã¿è¾¼ã¿ã—ã¦ã€å±¥æ­´ã‚’ãƒãƒ£ãƒƒãƒˆæ¬„ã«åæ˜ 
                        st.rerun()

            except Exception as e:
                st.error(f"ãƒ—ãƒªã‚»ãƒƒãƒˆè³ªå•ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º (å…¨ã‚¿ãƒ–å…±é€š) ---
# st.tabsã®å¤–å´ã«é…ç½®ã™ã‚‹ã“ã¨ã§ã€ã‚¿ãƒ–ã‚’åˆ‡ã‚Šæ›¿ãˆã¦ã‚‚å±¥æ­´ãŒå¸¸ã«è¦‹ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹
st.divider() # åŒºåˆ‡ã‚Šç·š
st.subheader("ğŸ’¬ ãƒˆã‚¹ã¨ã®ä¼šè©±")

chat_container = st.container(height=400) # é«˜ã•ã‚’å›ºå®šã—ãŸãƒãƒ£ãƒƒãƒˆã‚³ãƒ³ãƒ†ãƒŠ
with chat_container:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹ (å…¨ã‚¿ãƒ–å…±é€š) ---
if prompt := st.chat_input("Kenã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã‚Œï¼"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ ãƒ»è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with chat_container.chat_message("user"): # ã‚³ãƒ³ãƒ†ãƒŠå†…ã«è¿½åŠ 
        st.markdown(prompt)

    # AIã«å¿œç­”ã‚’ç”Ÿæˆã•ã›ã¦è¡¨ç¤º
    try:
        # Geminiã«ãƒ•ãƒªãƒ¼ãƒˆãƒ¼ã‚¯ã•ã›ã‚‹
        response = st.session_state.chat.send_message(prompt)
        response_text = response.text
        
        # AIã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ ãƒ»è¡¨ç¤º
        with chat_container.chat_message("assistant"): # ã‚³ãƒ³ãƒ†ãƒŠå†…ã«è¿½åŠ 
            st.markdown(response_text)
        st.session_state.messages.append({"role": "assistant", "content": response_text})
        
        # å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å°‘ã—å‰Šé™¤ï¼ˆãƒ¡ãƒ¢ãƒªå¯¾ç­– - ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if len(st.session_state.messages) > 50:
             st.session_state.messages = st.session_state.messages[-50:]
             
    except Exception as e:
        st.error(f"AIã¨ã®é€šä¿¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")