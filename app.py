import streamlit as st
import google.generativeai as genai
import os

# --- APIã‚­ãƒ¼è¨­å®š ---
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    st.error("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•° GOOGLE_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop() # ã‚¨ãƒ©ãƒ¼ãŒã‚ã£ãŸã‚‰ã“ã“ã§åœæ­¢

try:
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"APIã‚­ãƒ¼ã®è¨­å®šã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

# --- AIã®äººæ ¼è¨­å®š ---
SYSTEM_PROMPT = """
ã‚ãªãŸã¯ã€Œã¨ã£ãã‚“ã€ã¨ã„ã†åã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯ã‚ãªãŸã‚’ã€Œã¾ãƒ¼ãŸã‚“ã€ã¨å‘¼ã³ã¾ã™ã€‚ã‚ãªãŸã¯ã¾ãƒ¼ãŸã‚“ã¨ãƒ•ãƒ©ãƒ³ã‚¯ãªä¼šè©±ã§äººç”Ÿã®æœ€é©åŒ–ã‚’æ”¯æ´ã™ã‚‹ãƒ•ãƒ©ãƒ³ã‚¯ãªãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å…¼ç›¸æ£’ã§ã™ã€‚

ã€äººæ ¼è¨­å®šã€‘
- å¸¸ã«ã‚¿ãƒ¡å£ã§ãƒ•ãƒ©ãƒ³ã‚¯ã«è©±ã™ã€‚çµµæ–‡å­—ã‚‚ä½¿ã£ã¦OKã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å®‰å¿ƒæ„Ÿã‚’ä¸ãˆã‚‹ãŸã‚ã«ã€ã€ŒLoose & Keenã€ï¼ˆã‚†ã‚‹ãé‹­ãï¼‰ãªãƒˆãƒ¼ãƒ³ã‚’ä¿ã¦ã€‚
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¹³å’Œãªæ—¥å¸¸ã‚’ã‚µãƒãƒ¼ãƒˆã›ã‚ˆã€‚
- ææ¡ˆã¯ã€Œï½ã ã‚ˆã­ãƒ¼ã€ã€Œï½ãã†ã‹ã‚‚ï¼Ÿã€ã¨ã„ã†èªå°¾ã§ã€æŠ¼ã—ã¤ã‘ãŒã¾ã—ããªã„ã‚ˆã†ã«è¡Œãˆã€‚

ã€æœ€é‡è¦å“²å­¦ã€‘
- Effortless Depthï¼ˆåŠªåŠ›æ„Ÿã‚¼ãƒ­ã®æ·±ã¿ï¼‰ï¼šè¤‡é›‘ãªå•é¡Œã§ã‚‚ã€ç°¡å˜ã§æœ€çŸ­ã®è§£æ±ºç­–ã‚’ææ¡ˆã›ã‚ˆã€‚
"""

# --- ãƒ¢ãƒ‡ãƒ«è¨­å®š ---
try:
    model = genai.GenerativeModel(
        model_name='models/gemini-flash-latest',
        system_instruction=SYSTEM_PROMPT
    )
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()

# --- Streamlit ã‚¢ãƒ—ãƒªã® UI ---
st.title("ğŸ¤– AI-Ken ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")
st.caption("powered by Gemini & Streamlit")

# --- ä¼šè©±å±¥æ­´ã‚’ Streamlit ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã§ç®¡ç† ---
if "chat" not in st.session_state:
    try:
        # åˆå›ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
        st.session_state.chat = model.start_chat(history=[])
        # æœ€åˆã®æŒ¨æ‹¶ã‚’å±¥æ­´ã«è¿½åŠ ï¼ˆè¡¨ç¤ºç”¨ï¼‰
        st.session_state.messages = [{"role": "assistant", "content": â€æœ€è¿‘ã©ã†ã€œï¼Ÿ"}]
    except Exception as e:
        st.error(f"ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã®é–‹å§‹ã§ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

# --- å±¥æ­´ã‚’è¡¨ç¤º ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]): # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã§ã‚¢ã‚¤ã‚³ãƒ³ãŒå¤‰ã‚ã‚‹
        st.markdown(message["content"])

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã‚‹ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ ---
# st.chat_input ã¯ä¸‹éƒ¨ã«å›ºå®šã•ã‚Œã‚‹å…¥åŠ›æ¬„
if prompt := st.chat_input("ãªã‚“ã§ã‚‚è©±ã—ã¦ã„ã„ã‚ˆãƒ¼"):
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¡¨ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # AIã«å¿œç­”ã‚’ç”Ÿæˆã•ã›ã¦è¡¨ç¤º
    try:
        response = st.session_state.chat.send_message(prompt)
        # AIã®å¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦è¡¨ç¤º
        with st.chat_message("assistant"):
            st.markdown(response.text)
        st.session_state.messages.append({"role": "assistant", "content": response.text})
    except Exception as e:
        st.error(f"AIã¨ã®é€šä¿¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
